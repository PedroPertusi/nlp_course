{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Prova 1\n",
    "\n",
    "Nesta prova, utilizaremos um dataset fornecido por uma empresa de e-commerce. Trata-se de um dataset que contém reviews de pedidos feitos na Internet ou através do aplicativo. Cada review tem uma nota (*score*) que vai de 1 (muito ruim) a 5 (muito bom). Também, cada review tem uma mensagem deixada pelo cliente, que pode esclarecer o que levou à atribuição da nota. O dataset é o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>5</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>5</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8670d52e15e00043ae7de4c01cc2fe06</td>\n",
       "      <td>4</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b49719c8a200003f700d3d986ea1a19</td>\n",
       "      <td>4</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3948b09f7c818e2d86c9a546758b2335</td>\n",
       "      <td>5</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  review_score  \\\n",
       "0  e64fb393e7b32834bb789ff8bb30750e             5   \n",
       "1  f7c4243c7fe1938f181bec41a392bdeb             5   \n",
       "2  8670d52e15e00043ae7de4c01cc2fe06             4   \n",
       "3  4b49719c8a200003f700d3d986ea1a19             4   \n",
       "4  3948b09f7c818e2d86c9a546758b2335             5   \n",
       "\n",
       "                              review_comment_message  \n",
       "0              Recebi bem antes do prazo estipulado.  \n",
       "1  Parabéns lojas lannister adorei comprar pela I...  \n",
       "2  aparelho eficiente. no site a marca do aparelh...  \n",
       "3    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n  \n",
       "4  Vendedor confiável, produto ok e entrega antes...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A empresa, porém, gostaria de saber quais são os aspectos em que pode melhorar. Para fazer isso, jogou todos os reviews em um LLM (o procedimento para isso está em `consultar_llm.py`, que acompanha este notebook), e então coletou as respostas. Em sua execução, o LLM retornou o seguinte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESPOSTA DO LLM\n",
    "\n",
    "Para identificar os elementos mais elogiados e reclamados, vou analisar as avaliações buscando palavras-chave e temas recorrentes.\n",
    "\n",
    "**Elogios Mais Comuns:**\n",
    "\n",
    "*   **Entrega Rápida/No Prazo:** Este é o elogio mais frequente. Termos como \"chegou antes do prazo\", \"entrega rápida\", \"no prazo\" aparecem repetidamente.\n",
    "*   **Produto Bom/Excelente Qualidade:** Muitos clientes expressam satisfação com a qualidade do produto em si. Palavras como \"excelente\", \"bom\", \"perfeito\", \"recomendo\", \"atendeu minhas expectativas\", \"cumpre o que promete\" são comuns.\n",
    "*   **Bom Atendimento/Comunicação:** Alguns clientes elogiam a comunicação clara e eficiente com o vendedor.\n",
    "*   **Embalagem:** Alguns clientes elogiaram a forma como o produto foi embalado.\n",
    "\n",
    "**Reclamações Mais Comuns:**\n",
    "\n",
    "*   **Não Recebimento do Produto:** Esta é a reclamação mais grave e frequente. Várias avaliações mencionam \"não recebi o produto\" ou \"ainda não recebi\".\n",
    "*   **Atraso na Entrega:** Mesmo quando o produto é entregue, o atraso é uma reclamação comum.\n",
    "*   **Produto com Defeito/Danificado:** Alguns clientes relatam receber produtos com defeito, amassados ou com peças faltando.\n",
    "*   **Produto Errado:** Alguns clientes relatam ter recebido o produto errado.\n",
    "*   **Problemas com a Compra/Cancelamento:** Alguns clientes relatam problemas com o cancelamento da compra.\n",
    "*   **Problemas com a Comunicação:** Alguns clientes reclamam da dificuldade em se comunicar com o vendedor após a compra ou da falta de resposta às suas dúvidas.\n",
    "*   **Voltagem Errada:** Um cliente reclamou que o produto veio com a voltagem errada.\n",
    "*   **Qualidade do Produto Abaixo do Esperado:** Alguns clientes expressam insatisfação com a qualidade do produto, mencionando material ruim, acabamento imperfeito ou falsificação.\n",
    "*   **Problemas com a Entrega pelos Correios:** Um cliente reclamou do serviço dos correios.\n",
    "\n",
    "**Resumo:**\n",
    "\n",
    "*   **Elogios:** Entrega rápida/no prazo e boa qualidade do produto são os pontos fortes.\n",
    "*   **Reclamações:** Problemas com a entrega (não recebimento, atraso) e produtos com defeito/qualidade inferior são os principais pontos fracos.\n",
    "\n",
    "**Recomendações:**\n",
    "\n",
    "A empresa deve priorizar a melhoria dos processos de entrega para garantir que os produtos cheguem aos clientes no prazo e em perfeitas condições. Além disso, deve investir no controle de qualidade dos produtos e na comunicação com os clientes para resolver problemas de forma rápida e eficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussão\n",
    "\n",
    "Mesmo que o LLM possa dar pistas importantes para o desenvolvimento desta solução, há um problemaa fundamental em simplesmente \"acreditar\" nessa resposta: ela não tem base em dados nem em uma metodologia científica, então é impossível criticá-la, replicá-la ou saber de suas limitações.\n",
    "\n",
    "A tarefa neste exercício é encontrar dados, usando metodologias clássicas de NLP, que corroborem ou que contradigam a conclusão trazida pelo LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "\n",
    "Faça e avalie (usando uma métrica) um modelo preditivo baseado no modelo Bag-of-Words capaz de prever, à partir do texto do review, se ele será positivo (notas 4 ou 5) ou negativo (notas 1, 2 ou 3). Use estratégias adequadas para mostrar que o modelo não está enviesado (por exemplo, retornando sempre 'positivo' para o review). Justifique todas as suas decisões (tipo de vetorizador, tipo de classificador, métrica(s) usada(s) para avaliação) em comentários no código.\n",
    "\n",
    "Dica: `df['positivo'] = df['review_score'].apply(lambda x: x > 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de revies positivos: 26530 | % de reviews positivos: 64.74%\n",
      "Total de revies negativos: 14447 | % de reviews negativos: 35.26%\n",
      "\n",
      "Acurácia do modelo: 0.86%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.75      0.79      2900\n",
      "        True       0.87      0.92      0.89      5296\n",
      "\n",
      "    accuracy                           0.86      8196\n",
      "   macro avg       0.85      0.83      0.84      8196\n",
      "weighted avg       0.86      0.86      0.86      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#exercicio1\n",
    "#não apague o comentário acima!!!\n",
    "# Faça todo o seu código (e também os comentários) nesta célula!\n",
    "\n",
    "# Primeiramente criaremos uma coluna para nosso dataset que será nosso Y, basicamente expressando 1 (True) caso o review seja positivo e 0 \n",
    "# (False) caso o review seja negativo\n",
    "\n",
    "df['positivo'] = df['review_score'].apply(lambda x: x > 3)\n",
    "total_reviews_positivos = df[df['positivo'] == True]['positivo'].count()\n",
    "total_reviews_negativos = df[df['positivo'] == False]['positivo'].count()\n",
    "\n",
    "print(f'Total de revies positivos: {total_reviews_positivos} | % de reviews positivos: {total_reviews_positivos / (total_reviews_positivos + total_reviews_negativos) * 100:.2f}%')\n",
    "print(f'Total de revies negativos: {total_reviews_negativos} | % de reviews negativos: {total_reviews_negativos / (total_reviews_positivos + total_reviews_negativos) * 100:.2f}%\\n')\n",
    "\n",
    "# Carregando arquivo de stopwords em portugues, link: https://gist.github.com/alopes/5358189\n",
    "stopwords = open(\"stopwords.txt\", \"r\") \n",
    "stopwords_data = stopwords.read() \n",
    "data_into_list = stopwords_data.strip()\n",
    "data_into_list = data_into_list.replace(' ','').replace('\\n', '.').split(\".\") \n",
    "stopwords.close() \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Criando a pipeline que contem nosso vetorizador e nosso classificador\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(binary=True, stop_words=data_into_list, min_df=3, max_df=0.8)),\n",
    "    ('classifier', BernoulliNB())\n",
    "])\n",
    "\n",
    "# Vetorizador: para o vetorizador vamos usar o CountVectorizer do sklearn, que tem como função converter uma coleção de textos em uma matriz de contagem dos \n",
    "# nossos tokens. Como nosso classificador é baseado na distribuição de Bernoulli, modelo binario, que considera apenas a presença ou ausência de uma feature \n",
    "# setamos binary=True para que cada palavra no documento seja transofrmada em 1 ou 0, indicando a presença ou ausência da palavra.\n",
    "# Além disso consideramos e removemos as stopwords em português da lista de tokens para evitar sua influência sobre o classificador. \n",
    "# Por fim no vetorizador também configuramos os parâmetros min_df e max_df aonde p valor absoluto ou fracionario representa, a frequência mínima/máxima de um termo,\n",
    "# neste caso colocamos o valor absoluto 3 como min_df, aonde basicamente descartamos palavras com 3 ou menos aparições e max_df palavras com uma taxa de aparição\n",
    "# maior que 80% nos textos, isso ajuda com problemas futuros de outliers e evita que nosso classificador lide com o tão temido \"overfitting\".\n",
    "\n",
    "# Classificador:\n",
    "# O modelo escolhido é BernoulliNB é construido em cima da distribuição de Bernoulli, que basicamente classifica em resultados binarios baseado na presença \n",
    "# ou ausência de features, seguindo nesse caso a idéia de modelo Bag-of-Words. A idéia é basicamente que o classificador recebe o vetor mencionado acima que \n",
    "# descreve o conteudo do dataset (nesse caso os tokens), e então o classificador usa esse vetor x que representa a probabilidade que aquele item (palavra) \n",
    "# esteja presente e logo corresponde a cada uma das classes conhecidas, e a partir da probabilidade das mesmas classifica então nesse caso o review como \n",
    "# positivo ou negativo (baseado nas palavras/tokens presentes)\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review_comment_message'], df['positivo'], test_size=0.2)\n",
    "\n",
    "# Treinar a pipeline \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia do modelo: {accuracy:.2f}%\\n')\n",
    "\n",
    "# Como pode ser observado no print da célula acima, obtivemos uma acurácia de 85%, agora iremos avaliar o resultado do \n",
    "# modelo preditivo para garantir que o mesmo não esteja eviesado.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Utilizamos o classification_report do sklearn.metrics para tirar algumas métricas do nosso modelo, nesse caso temos o valor absoluto chutado por ele para cada \n",
    "# possível resultado, nesse caso ele considerou 2894 avaliações como negativas e 5302 como positivas algo que parece fazer sentido até considerando nosso dataset \n",
    "# que como mostrado acima possui uma taxa de aproximadamente 65% de reviews positivos e 35% de reviews negativos. Outro ponto importante é que ele não está chutando\n",
    "# apenas uma única resposta. \n",
    "# Outra métrica interessante é considerarmos o precision e recall para cada um dos casos: \n",
    "# Quando olhamos para o precision 0.84 e recall 0.74 dos reviews negativos e precision 0.86 e recall 0.92 dos reviews positivos podemos inferir que nosso modelo\n",
    "# é menos confiante quando classificando os reviews negativos ao contrário dos positivos, por isso a diferença de recall entre os mesmos, \n",
    "# entretanto a precisão é bem semelhante entre ambos, enfatizando em uma taxa de acerto proporcional para ambos os casos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "\n",
    "Analise seu modelo e encontre quais são as palavras e/ou n-gramas que são melhores preditoras do número de estrelas (alto ou baixo) recebido um review (dica: você pode usar `pipeline[:-1].get_feature_names_out()` para encontrar uma lista com todos os tokens do seu vocabulário). Ao usar elementos do sklearn, use um comentário no código para explicar o que esses elementos significam e como eles podem apontar para o poder preditivo de cada palavra (ou n-grama). Por fim, use comentários no código para explicar como suas descobertas corroboram, contradizem, ou relativizam o que foi proposto pelo LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores palavras preditoras de reviews negativos e sua probabilidade: [('pessima', np.float64(0.503474857199898)), ('ressarcimento', np.float64(0.503474857199898)), ('tento', np.float64(0.503474857199898)), ('estorno', np.float64(0.5042114005393379)), ('lamentável', np.float64(0.5158034729090769))]\n",
      "Melhores palavras preditoras de reviews positivas e sua probabilidade: [('show', np.float64(0.9994476839700426)), ('amei', np.float64(0.9993417862561389)), ('adorei', np.float64(0.9992589020116213)), ('parabéns', np.float64(0.9992163228310875)), ('excelente', np.float64(0.9991388104959608))]\n",
      "Melhores palavras preditoras de reviews negativos: ['pessima', 'ressarcimento', 'tento', 'estorno', 'lamentável']\n",
      "Melhores palavras preditoras de reviews positivas: ['show', 'amei', 'adorei', 'parabéns', 'excelente']\n"
     ]
    }
   ],
   "source": [
    "#exercicio2\n",
    "#não apague o comentário acima!!!\n",
    "# Faça todo o seu código (e também os comentários) nesta célula!\n",
    "\n",
    "# A linha abaixo encontra uma lista com todos os tokens do nosso vocabulário\n",
    "tokens = model[:-1].get_feature_names_out()\n",
    "lista_tokens = []\n",
    "\n",
    "# A idéia é basicamente ir inteirando por todos os tokens e utlizando a função predict_proba do sklearn que retorna a probabilidade do token pertencer a classe\n",
    "# dada suas características e assim conseguimos inferir que aqueles que apresentarem a maior diferença entre as probabilidades são as palavras melhores preditoras\n",
    "# de um review bom (número de estrelas altos) e aquele que apresentar uma menor diferença entre as probabilidade \n",
    "# o melhor preditor de uma review ruim (número de estrelas baixos)\n",
    "\n",
    "\n",
    "for token in tokens:\n",
    "    proba = model.predict_proba([token])[0]\n",
    "    if proba[0] > proba[1]:\n",
    "        lista_tokens.append((token,proba[0]))\n",
    "    else:\n",
    "        lista_tokens.append((token,proba[1]))\n",
    "\n",
    "\n",
    "sorted_by_second = sorted(lista_tokens, key=lambda tup: tup[1])\n",
    "\n",
    "# Abaixo pegamos a lista e olhamos para os primeiros 5 e ultimos 5 elementos da lista ordenada baseada no valor encontrado e então separamos apenas a palavra\n",
    "# formando assim duas listas, uma com as palavras para reviews positivas e outra para negativas.\n",
    "top5_words_negative = [i[0] for i in sorted_by_second[0:5]]\n",
    "top5_words_positive = [i[0] for i in list(reversed(sorted_by_second))[0:5]]\n",
    "\n",
    "print(f'Melhores palavras preditoras de reviews negativos e sua probabilidade: {sorted_by_second[0:5]}')\n",
    "print(f'Melhores palavras preditoras de reviews positivas e sua probabilidade: {list(reversed(sorted_by_second))[0:5]}')\n",
    "\n",
    "print(f'Melhores palavras preditoras de reviews negativos: {top5_words_negative}')\n",
    "print(f'Melhores palavras preditoras de reviews positivas: {top5_words_positive}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rubricas e auto-avaliação assistida por IA\n",
    "\n",
    "Este teste tem duas questões. Porém, são questões bastante complexas. Para verificar se você não esqueceu de nada em nenhuma questão, você pode usar o script `autoavaliacao.py`.\n",
    "\n",
    "Cada um dos ítens cumpridos corretamente nas rubricas disponíveis em `autoavaliacao.py` terão o mesmo valor nas questões (1/8 na questão 1, 1/4 na questão 2). Um ítem cumprido parcialmente vale metade dos pontos. Um ítem feito errado não vale pontos. Cada uma das questões tem o mesmo valor (50% do total).\n",
    "\n",
    "**IMPORTANTE**: o fato de o LLM dizer que um ítem da rubrica foi cumprido, não significa que ele **realmente** foi cumprido. O LLM avalia apenas se o ítem **existe**. O LLM é uma **ferramenta** e a sua utilidade depende do **seu** julgamento crítico.\n",
    "\n",
    "Após o término da prova, salve seu notebook e entregue no Blackboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação da prova\n",
    "\n",
    "Se desejar, comente os pontos abaixo:\n",
    "\n",
    "**Experiência da prova**: ao fazer esta prova, me senti...\n",
    "\n",
    "**Dificuldades técnicas ou de compreensão do enunciado**: ...\n",
    "\n",
    "**O script de auto-avaliação me ajudou**: sim, não, em partes...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
